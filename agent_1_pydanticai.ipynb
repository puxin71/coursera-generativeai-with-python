{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3921db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"pydantic-ai[all]\" litellm opentelemetry-sdk opentelemetry-exporter-otlp python-dotenv pip-system-certs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae461902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi in c:\\users\\cpu\\cindys\\coursera\\coursera-generativeai-with-python\\.venv\\lib\\site-packages (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006981a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\".env\",              # load from .env\n",
    "        env_file_encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "    openrouter_api_key: str\n",
    "    openrouter_base_url: str = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627aefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cpu\\AppData\\Local\\Temp\\ipykernel_34644\\2588355798.py:38: DeprecationWarning: Use ConsoleLogRecordExporter. Since logs are not stable yet this WILL be removed in future releases.\n",
      "  BatchLogRecordProcessor(ConsoleLogExporter())\n",
      "2025-12-29 23:29:41,788 [INFO] openrouter_agent - Starting run_agent_query...\n",
      "2025-12-29 23:29:42,195 [INFO] openai._base_client - Retrying request to /chat/completions in 0.441977 seconds\n",
      "2025-12-29 23:29:42,786 [INFO] openai._base_client - Retrying request to /chat/completions in 0.902715 seconds\n",
      "2025-12-29 23:29:43,927 [INFO] openai._base_client - Retrying request to /chat/completions in 0.406654 seconds\n",
      "2025-12-29 23:29:44,449 [INFO] openai._base_client - Retrying request to /chat/completions in 0.884530 seconds\n",
      "2025-12-29 23:29:46,776 [INFO] openrouter_agent - run_agent_query finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent answer:\n",
      "Hello! It sounds like you might be experiencing some technical difficulties. Have you tried turning your computer or modem off and then back on? This often resolves many common issues. Give that a try and let me know if you still need assistance!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"chat mistralai/devstral-2512:free\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xc3b48d25b661b28c9275fed8737aab86\",\n",
      "        \"span_id\": \"0xeac28e1262a9cf90\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": \"0xd2cb22c4b9274a07\",\n",
      "    \"start_time\": \"2025-12-30T04:29:41.791356Z\",\n",
      "    \"end_time\": \"2025-12-30T04:29:46.776052Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"gen_ai.operation.name\": \"chat\",\n",
      "        \"gen_ai.system\": \"litellm\",\n",
      "        \"gen_ai.request.model\": \"mistralai/devstral-2512:free\",\n",
      "        \"server.address\": \"openrouter.ai\",\n",
      "        \"model_request_parameters\": \"{\\\"function_tools\\\": [], \\\"builtin_tools\\\": [], \\\"output_mode\\\": \\\"text\\\", \\\"output_object\\\": null, \\\"output_tools\\\": [], \\\"prompted_output_template\\\": null, \\\"allow_text_output\\\": true, \\\"allow_image_output\\\": false}\",\n",
      "        \"gen_ai.input.messages\": \"[{\\\"role\\\": \\\"system\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\\\"}]}, {\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"test\\\"}]}]\",\n",
      "        \"gen_ai.output.messages\": \"[{\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Hello! It sounds like you might be experiencing some technical difficulties. Have you tried turning your computer or modem off and then back on? This often resolves many common issues. Give that a try and let me know if you still need assistance!\\\"}], \\\"finish_reason\\\": \\\"stop\\\"}]\",\n",
      "        \"logfire.json_schema\": \"{\\\"type\\\": \\\"object\\\", \\\"properties\\\": {\\\"gen_ai.input.messages\\\": {\\\"type\\\": \\\"array\\\"}, \\\"gen_ai.output.messages\\\": {\\\"type\\\": \\\"array\\\"}, \\\"model_request_parameters\\\": {\\\"type\\\": \\\"object\\\"}}}\",\n",
      "        \"gen_ai.usage.input_tokens\": 39,\n",
      "        \"gen_ai.usage.output_tokens\": 49,\n",
      "        \"gen_ai.response.model\": \"mistralai/devstral-2512:free\",\n",
      "        \"gen_ai.response.id\": \"gen-1767068985-s991Ttbuu1EZubxNcE33\",\n",
      "        \"gen_ai.response.finish_reasons\": [\n",
      "            \"stop\"\n",
      "        ]\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.39.1\",\n",
      "            \"service.name\": \"openrouter-agent\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"name\": \"agent run\",\n",
      "    \"context\": {\n",
      "        \"trace_id\": \"0xc3b48d25b661b28c9275fed8737aab86\",\n",
      "        \"span_id\": \"0xd2cb22c4b9274a07\",\n",
      "        \"trace_state\": \"[]\"\n",
      "    },\n",
      "    \"kind\": \"SpanKind.INTERNAL\",\n",
      "    \"parent_id\": null,\n",
      "    \"start_time\": \"2025-12-30T04:29:41.790525Z\",\n",
      "    \"end_time\": \"2025-12-30T04:29:46.776616Z\",\n",
      "    \"status\": {\n",
      "        \"status_code\": \"UNSET\"\n",
      "    },\n",
      "    \"attributes\": {\n",
      "        \"model_name\": \"fallback:google/gemini-2.0-flash-exp:free,nex-agi/deepseek-v3.1-nex-n1:free,mistralai/devstral-2512:free\",\n",
      "        \"agent_name\": \"agent\",\n",
      "        \"gen_ai.agent.name\": \"agent\",\n",
      "        \"logfire.msg\": \"agent run\",\n",
      "        \"final_result\": \"Hello! It sounds like you might be experiencing some technical difficulties. Have you tried turning your computer or modem off and then back on? This often resolves many common issues. Give that a try and let me know if you still need assistance!\",\n",
      "        \"gen_ai.usage.input_tokens\": 39,\n",
      "        \"gen_ai.usage.output_tokens\": 49,\n",
      "        \"pydantic_ai.all_messages\": \"[{\\\"role\\\": \\\"system\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\\\"}]}, {\\\"role\\\": \\\"user\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"test\\\"}]}, {\\\"role\\\": \\\"assistant\\\", \\\"parts\\\": [{\\\"type\\\": \\\"text\\\", \\\"content\\\": \\\"Hello! It sounds like you might be experiencing some technical difficulties. Have you tried turning your computer or modem off and then back on? This often resolves many common issues. Give that a try and let me know if you still need assistance!\\\"}], \\\"finish_reason\\\": \\\"stop\\\"}]\",\n",
      "        \"logfire.json_schema\": \"{\\\"type\\\": \\\"object\\\", \\\"properties\\\": {\\\"pydantic_ai.all_messages\\\": {\\\"type\\\": \\\"array\\\"}, \\\"final_result\\\": {\\\"type\\\": \\\"object\\\"}}}\"\n",
      "    },\n",
      "    \"events\": [],\n",
      "    \"links\": [],\n",
      "    \"resource\": {\n",
      "        \"attributes\": {\n",
      "            \"telemetry.sdk.language\": \"python\",\n",
      "            \"telemetry.sdk.name\": \"opentelemetry\",\n",
      "            \"telemetry.sdk.version\": \"1.39.1\",\n",
      "            \"service.name\": \"openrouter-agent\"\n",
      "        },\n",
      "        \"schema_url\": \"\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import httpx\n",
    "import asyncio\n",
    "\n",
    "from litellm import completion\n",
    "from openai import RateLimitError\n",
    "from opentelemetry.sdk._logs import LoggerProvider\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor, ConsoleSpanExporter\n",
    "from opentelemetry.sdk._logs.export import BatchLogRecordProcessor, ConsoleLogExporter\n",
    "\n",
    "from pydantic_ai import Agent, InstrumentationSettings, ModelSettings\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.litellm import LiteLLMProvider\n",
    "from pydantic_ai.models.openrouter import OpenRouterModelSettings\n",
    "\n",
    "from pydantic_ai.exceptions import ModelHTTPError\n",
    "from pydantic_ai.models.fallback import FallbackModel\n",
    "\n",
    "# ---------- Basic logging ----------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(\"openrouter_agent\")\n",
    "\n",
    "# ---------- OpenTelemetry setup ----------\n",
    "resource = Resource.create({\"service.name\": \"openrouter-agent\"})\n",
    "\n",
    "tracer_provider = TracerProvider(resource=resource)\n",
    "tracer_provider.add_span_processor(\n",
    "    BatchSpanProcessor(ConsoleSpanExporter())\n",
    ")\n",
    "\n",
    "logger_provider = LoggerProvider(resource=resource)\n",
    "logger_provider.add_log_record_processor(\n",
    "    BatchLogRecordProcessor(ConsoleLogExporter())\n",
    ")\n",
    "\n",
    "instrumentation_settings = InstrumentationSettings(\n",
    "    tracer_provider=tracer_provider,\n",
    "    logger_provider=logger_provider\n",
    ")\n",
    "\n",
    "# ---------- PydanticAI agent (Functional approach) ----------\n",
    "from typing import Callable, Awaitable\n",
    "from functools import partial\n",
    "\n",
    "# Pure function to create provider configuration\n",
    "def create_provider_config(settings:Settings, http_client: httpx.AsyncClient) -> dict:\n",
    "    \"\"\"Pure function returning provider configuration.\"\"\"\n",
    "    return {\n",
    "        \"api_base\": settings.openrouter_base_url,\n",
    "        \"api_key\": settings.openrouter_api_key,\n",
    "        \"http_client\": http_client, \n",
    "    }\n",
    "\n",
    "# Pure function to create model settings\n",
    "def create_model_settings() -> ModelSettings:\n",
    "    return ModelSettings(\n",
    "        max_tokens=500,\n",
    "    )\n",
    "\n",
    "# Functional composition: provider -> model -> agent\n",
    "def build_provider(config: dict) -> LiteLLMProvider:\n",
    "    \"\"\"Build provider from configuration.\"\"\"\n",
    "    return LiteLLMProvider(\n",
    "        api_key=config.get(\"api_key\",  None),\n",
    "        http_client=config.get(\"http_client\", None),\n",
    "        api_base=config.get(\"api_base\", None),\n",
    "    )\n",
    "\n",
    "def build_model(provider: LiteLLMProvider) -> FallbackModel:\n",
    "    \"\"\"Build model with provider.\"\"\"\n",
    "    openrouter_models=[\n",
    "        \"google/gemini-2.0-flash-exp:free\",\n",
    "        \"nex-agi/deepseek-v3.1-nex-n1:free\",   # Fallback 1\n",
    "        \"mistralai/devstral-2512:free\",        # Fallback 2\n",
    "    ]\n",
    "\n",
    "    # Create model instances for the fallback models\n",
    "    model_instances: list[OpenAIChatModel] = []\n",
    "    for model_name in openrouter_models:\n",
    "        model = OpenAIChatModel(\n",
    "            model_name=model_name,\n",
    "            provider=provider,\n",
    "            settings=create_model_settings(),\n",
    "        )\n",
    "        model_instances.append(model)\n",
    "\n",
    "    # Initialize FallbackModel with a default and fallbacks\n",
    "    # The first model in the list is used as the default_model    \n",
    "    fallbacks = FallbackModel(\n",
    "        model_instances[0],\n",
    "        *model_instances[1:]  # Pass as list, not unpacked\n",
    "    )\n",
    "    \n",
    "    return fallbacks\n",
    "\n",
    "def build_agent(model: FallbackModel, system_prompt: str) -> Agent:\n",
    "    \"\"\"Build agent with model and instrumentation.\"\"\"\n",
    "    return Agent(\n",
    "        model,\n",
    "        system_prompt=system_prompt,\n",
    "        instrument=instrumentation_settings\n",
    "    )\n",
    "\n",
    "# Fluent builder pattern for agent creation\n",
    "def create_agent(http_client: httpx.AsyncClient) -> Agent:\n",
    "    \"\"\"\n",
    "    Fluent pipeline for agent creation.\n",
    "    Settings -> Provider -> Model -> Agent\n",
    "    \"\"\"\n",
    "    SYSTEM_PROMPT = \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"\n",
    "    \n",
    "    settings = Settings()\n",
    "    config = create_provider_config(settings, http_client)\n",
    "    provider = build_provider(config)\n",
    "    model = build_model(provider)\n",
    "    return build_agent(model, SYSTEM_PROMPT)\n",
    "\n",
    "def with_logging(func: Callable[..., Awaitable]) -> Callable[..., Awaitable]:\n",
    "    \"\"\"Decorator for adding logging to async functions.\"\"\"\n",
    "    async def wrapper(*args, **kwargs):\n",
    "        logger.info(f\"Starting {func.__name__}...\")\n",
    "        result = await func(*args, **kwargs)\n",
    "        logger.info(f\"{func.__name__} finished.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Pure async function for running agent query\n",
    "@with_logging\n",
    "async def run_agent_query(agent: Agent, question: str, retries: int = 1) -> str:\n",
    "    \"\"\"Pure async function to run agent query and return output.\"\"\"\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            result = await agent.run(question)\n",
    "            return result.output\n",
    "        except ModelHTTPError as e:\n",
    "            if e.status_code == 429:\n",
    "                logger.warning(f\"OpenRouter 429 rate limit: {e.body}. Retrying...\")\n",
    "                if i < retries - 1:\n",
    "                    await asyncio.sleep((i + 1) * 5)\n",
    "                    continue\n",
    "            raise  # Re-raise non-429 or final retry       \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error: {e}\")\n",
    "            raise\n",
    "            \n",
    "# Compose the entire workflow\n",
    "async def execute_agent_workflow(http_client: httpx.AsyncClient, question: str) -> str:\n",
    "    \"\"\"\n",
    "    Functional workflow: create agent -> run query -> return result.\n",
    "    This is a pure functional pipeline.\n",
    "    \"\"\"\n",
    "    agent = create_agent(http_client)\n",
    "    return await run_agent_query(agent, question)\n",
    "\n",
    "# Main entry point using context manager and asyncio.run()\n",
    "async def main() -> None:\n",
    "    \"\"\"Main function with proper resource management.\"\"\"\n",
    "    question = input(\"What do you need help with?\")\n",
    "    \n",
    "    # Context manager for automatic resource cleanup (fluent Python)\n",
    "    async with httpx.AsyncClient(verify=False, timeout=60.0) as http_client:\n",
    "        answer = await execute_agent_workflow(http_client, question)\n",
    "        print(f\"Agent answer:\\n{answer}\")\n",
    "\n",
    "# Pythonic entry point\n",
    "if __name__ == \"__main__\":\n",
    "    await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
